{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A&A Project: Sentiment Analysis of Apple M1 in Twitter\n",
    "\n",
    "Author: Hongshen Lee\n",
    "\n",
    "Date:  2020/11/21\n",
    "\n",
    "## Step 2: Generate a Sentiment Model\n",
    "\n",
    "This part is to generate a model to do the sentiment analysis. This model take the sentences of one review or one tweet as input, and outputs the sentimens label, incluing positive or negative.\n",
    "\n",
    "To achieve this goal, I collect the data set of [Amazon Reviews](https://www.kaggle.com/bittlingmayer/amazonreviews) from Kaggle. This data set include 4,000,000 records.In the model phase, I use the Naive Bayes to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from string import punctuation\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Data Phase\n",
    "\n",
    "### Step 2.1.1: Read Data\n",
    "\n",
    "Read data from bz2 files and decode with utf-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.ft.txt.bz2', 'train.ft.txt.bz2']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/reviews\"\n",
    "\n",
    "print(os.listdir(data_path))\n",
    "\n",
    "train_file_path = data_path+ \"/train.ft.txt.bz2\"\n",
    "test_file_path = data_path + \"/test.ft.txt.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_BZ2File(train_file_path,test_file_path):\n",
    "    train_file = bz2.BZ2File(train_file_path)\n",
    "    test_file = bz2.BZ2File(test_file_path)\n",
    "    \n",
    "    train_file_lines  = train_file.readlines()\n",
    "    test_file_lines   = test_file.readlines()\n",
    "    \n",
    "    # Convert from raw binary strings to strings that can be parsed\n",
    "    train_file_lines  = [x.decode('utf-8') for x in train_file_lines]\n",
    "    test_file_lines   = [x.decode('utf-8') for x in test_file_lines]\n",
    "    \n",
    "    return train_file_lines,test_file_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1.2: Clean Data\n",
    "\n",
    "- Remove punctuation, stopwords,lowercase\n",
    "- Remove some raw url string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(origin_data):\n",
    "    sw = stopwords.words('english')\n",
    "    labels = [0 if s.split(' ')[0] == '__label__1' else 1 for s in origin_data]\n",
    "    sentences = [s.split(' ', 1)[1][:-1].lower() for s in origin_data]\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = re.sub('\\d','0',sentences[i])\n",
    "        sentences[i]  = re.sub(r'(www.|https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '',\n",
    "                            sentences[i], flags=re.MULTILINE)                \n",
    "                \n",
    "        sentence    = [w for w in sentences[i].split(' ') if w not in sw]\n",
    "        sentences[i]= [w for w in sentence if w not in punctuation]\n",
    "#         porter = nltk.PorterStemmer() \n",
    "#         sentences[i] = [porter.stem(w) for w in sentences[i]]\n",
    "    return labels,sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines,test_file_lines = read_data_from_BZ2File(train_file_path,test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n",
      "\n",
      "__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Data Sample\n",
    "print(train_file_lines[0])\n",
    "print(test_file_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1.3: Prepare Datasets\n",
    "\n",
    "- Create train and test datasets\n",
    "- Determine dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size to test the code and meet the memory limit \n",
    "train_set_size=5000\n",
    "test_set_size=500\n",
    "\n",
    "test_labels,test_sentences   = clean_data(test_file_lines[:test_set_size])\n",
    "train_labels,train_sentences = clean_data(train_file_lines[:train_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set =[]\n",
    "test_set  =[]\n",
    "\n",
    "for i in range(train_set_size):\n",
    "    train_set.append((train_sentences[i],train_labels[i]))\n",
    "    \n",
    "for i in range(test_set_size):\n",
    "    test_set.append((test_sentences[i],test_labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Model Phase\n",
    "\n",
    "### Step 2.2.1: Feature Extraction\n",
    "\n",
    "Define features of the sentence and apply the features to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features of the model\n",
    "def get_word_features(sentence_list):\n",
    "    wordlist=[]\n",
    "    for sentence in sentence_list:\n",
    "        wordlist.extend(sentence)\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "\n",
    "# Extract and apply the features to the data\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in w_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_features=get_word_features(train_sentences[1:train_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the features to the dataset\n",
    "train_set = [(extract_features(sentence), label) for (sentence, label) in train_set]\n",
    "test_set = [(extract_features(sentence), label) for (sentence, label) in test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2.2: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2.3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(correct_vs_prediction):\n",
    "    tn=0\n",
    "    tp=0\n",
    "    fn=0\n",
    "    fp=0\n",
    "    for (label, guess) in sorted(correct_vs_prediction):\n",
    "        if(guess==0):\n",
    "            if(label==0):\n",
    "                tn=tn+1\n",
    "            else:\n",
    "                fn=fn+1\n",
    "        else:\n",
    "            if(label==1):\n",
    "                tp=tp+1\n",
    "            else:\n",
    "                fp=fp+1\n",
    "    precision=tp/(tp+fp)\n",
    "    accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "    recall =tp/(tp+fn)\n",
    "    print('precision={:<8f} accuracy={:<8f} recall={:<8f}'.format(precision, accuracy, recall))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(waste) = True                0 : 1      =     30.7 : 1.0\n",
      "         contains(worst) = True                0 : 1      =     21.3 : 1.0\n",
      "     contains(horrible.) = True                0 : 1      =     18.6 : 1.0\n",
      "     contains(terrible.) = True                0 : 1      =     18.0 : 1.0\n",
      "     contains(defective) = True                0 : 1      =     16.3 : 1.0\n",
      "         contains(throw) = True                0 : 1      =     15.7 : 1.0\n",
      "      contains(classic:) = True                1 : 0      =     14.4 : 1.0\n",
      "         contains(awful) = True                0 : 1      =     14.0 : 1.0\n",
      "        contains(doesnt) = True                0 : 1      =     14.0 : 1.0\n",
      "          contains(bad.) = True                0 : 1      =     13.9 : 1.0\n",
      "            contains(:)) = True                1 : 0      =     13.6 : 1.0\n",
      "       contains(higgins) = True                0 : 1      =     12.3 : 1.0\n",
      "        contains(wasted) = True                0 : 1      =     12.2 : 1.0\n",
      "          contains(zero) = True                0 : 1      =     11.7 : 1.0\n",
      "        contains(hiking) = True                1 : 0      =     11.3 : 1.0\n",
      "        contains(price:) = True                1 : 0      =     11.3 : 1.0\n",
      "  contains(disappointed) = True                0 : 1      =     11.2 : 1.0\n",
      "    contains(ridiculous) = True                0 : 1      =     11.1 : 1.0\n",
      "          contains(send) = True                0 : 1      =     10.7 : 1.0\n",
      "         contains(smith) = True                1 : 0      =     10.5 : 1.0\n",
      " contains(disappointing) = True                0 : 1      =     10.1 : 1.0\n",
      "      contains(garbage.) = True                0 : 1      =     10.0 : 1.0\n",
      "       contains(scanner) = True                0 : 1      =     10.0 : 1.0\n",
      "      contains(customer) = True                0 : 1      =      9.9 : 1.0\n",
      "           contains(met) = True                1 : 0      =      9.7 : 1.0\n",
      "        contains(stupid) = True                0 : 1      =      9.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.881057 accuracy=0.828000 recall=0.772201\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for (features, label) in test_set:\n",
    "    guess = classifier.classify(features)\n",
    "    errors.append( (label, guess) )\n",
    "evaluate_model(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2.4: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('my_classifier.pickle', 'wb')\n",
    "pickle.dump(classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41276\n"
     ]
    }
   ],
   "source": [
    "print(len(w_features))\n",
    "file=open('features.txt','w',encoding=\"utf-8\")\n",
    "feature_str='\\n'.join(w_features)\n",
    "file.write(feature_str)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3 Conclusion \n",
    "\n",
    "This part finished the model training and saved the model for the next part.\n",
    "\n",
    "The accuracy of the model is 0.828, not very high. There are serval ways may improve the results:\n",
    "\n",
    "1. Better environment to support more data to train \n",
    "2. Better features engineering \n",
    "3. Better model building like Netural Network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
